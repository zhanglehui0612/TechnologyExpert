## 一 Redis是什么？可以干什么？Redis为什么这么快
### 1.1 Redis是什么
✅ 基于C语言实现的开源的内存数据库  

### 1.2 Redis应用场景
✅ 分布式缓存  
✅ 分布式锁  
✅ 发布和订阅  
✅ 排行榜  
✅ 计数器  

### 1.3 Redis为什么这么快
✅ 基于内存操作: Redis 所有数据都存储在内存中，访问速度比磁盘快几个数量级  
✅ 高效的数据结构  
✅ 单线程模型: Redis 使用 单线程处理客户端请求，避免了线程切换和加锁开销，提升性能  


## 二 Redis线程模型
### 2.1 Redis单线程模型
✅ Redis 服务端使用主线程运行事件循环，监听客户端连接和读写 I/O 事件  
✅ 当监听到客户端连接请求时，会建立连接，并将该连接注册到事件循环中  
✅ 当监听到客户端读写事件时，主线程会：  
1. [ ] 读取请求数据
2. [ ] 解析 RESP 协议命令
3. [ ] 执行命令逻辑（如对内存数据操作）
4. [ ] 将响应写回客户端  

✅ 以上所有操作均在一个线程（主线程）中串行完成，称为 单线程事件驱动模型  

### 2.2 Redis多线程模型
✅ 为提升网络 I/O 性能，Redis 从 6.x 开始引入了多线程处理网络读写  
✅ Redis 启动时会创建多个 I/O 线程，配合主线程工作  
✅ 客户端连接建立后，会被分配给某一个固定的 I/O 线程，后续该连接的读写操作始终由这个线程负责  
✅ 当监听到可读事件时，I/O 线程会读取 socket 中的数据，解析出完整命令，将其放入主线程的执行队列中  
✅ 主线程轮询这些命令队列，并按顺序 执行命令逻辑（仍是单线程执行）  
✅ 响应结果会通过 I/O线程发送回客户端  

📝 **总结:**   
➡️ Redis 6.x 之前是标准的 Reactor 单线程模型，所有请求都在主线程中串行处理  
➡️ Redis 6.x 后引入了多线程用于处理网络读写，将命令解析后交给主线程执行，既提升了吞吐，又保持了数据的一致性和线程安全   

### 2.3 为什么命令执行必须单线程
✅ 单线程执行命令避免了多线程环境下的竞争条件、锁和同步问题，使代码更加简单且稳定  
✅ 通过串行执行命令，Redis 能够保证所有命令的原子性和一致性  
✅ 瓶颈主要在网络I/O而不是命令执行，因此不需要对命令执行进行多线程处理  


## 三 Redis数据类型和结构
### 3.1 Redis数据类型
#### 3.1.1 字符串(String)
✅ 底层数据结构: SDS(简单动态字符串)  
✅ 适合高性能计数器、缓存值  

#### 3.1.3 List(Hash)
✅ 底层数据结构: 压缩列表(ziplist) + 双端链表(quicklist)  
✅ 小量元素: 用 ziplist，连续内存占用小; 大量元素或频繁操作：升级为双端链表quicklist  
✅ 适合队列、栈等使用场景  

#### 3.1.3 哈希(Hash)
✅ 底层数据结构: ziplist + hashtable  
✅ 数据量少采用ziplist; 数据量大采用hashtable  
✅ 适合存储一些对象缓存、用户会话信息、配置信息等场景  

#### 3.1.4 集合(Set)
✅ 底层数据结构: intset + hashtable  
✅ 数据量少且是整数，使用intset；数据量大或者非整数使用hashtable  
✅ 适合唯一且不重复场景: 比如黑名单、粉丝、关注集合等、在线用户收集等  

#### 3.1.5 有序集合(Zset)
✅ 底层数据结构: skiplist + hashtable  
✅ 每个元素带一个分数 score，自动按 score 排序  
✅ 适合排行榜、区间查询、分页等功能  

#### 3.1.6 位图(Bitmap)
✅ 用每一位 bit 表示一个用户/行为状态  
✅ 非常适合签到、活跃统计等  


### 3.2 数据结构
#### 3.2.1 sds
1. [ ] sds是simple dynamic string缩写，即简单动态字符串或者叫做可变长度字符串  
2. [ ] sds封装了一个char[]以及当前字符串长度  
3. [ ] sds支持自动扩容  
4. [ ] sds提供了多种格式，可以根据字符串长度自动选择  
5. [ ] sds获取长度也很高效，只需读取len字段即可，效率极高，不需要重新数一下当前字符串长度  
6. [ ] SDS还可以预先分配内存空间，避免频繁的申请内存空间，当字符传长度变大的时候，不一定需要重新分配内存，除非当前预分配的内存不足，这时候就需要扩容了

#### 3.2.2 ziplist
1. [ ] 本质是一个字节数组,是一个连续的内存结构  
2. [ ] 支持顺序读取、空间占用极小  
3. [ ] 优点: 节省内存，非常紧凑  
4. [ ] 缺点: 插入、删除元素需要移动大量内存，性能较差;越大越慢，尤其不适合频繁变更或大数据量  

#### 3.2.3 quicklist
1. [ ] quicklist = 多个 ziplist 组成的双向链表  
2. [ ] 每个节点是一个 ziplist，多个 ziplist 串联成链表  
3. [ ] 结合了 ziplist 的紧凑性 和 链表的快速插入删除  

#### 3.2.4 skiplist
✅ 优点:  
1. [ ] 插入/查找/删除都很快（接近平衡树但更简单实现）
2. [ ] 非常适合范围查找、分页、排序等操作,跳跃链表既可以实现查询和插入O(logN)时间复杂度

✅ 缺点:  
1. [ ] 内存开销比单链表大（多了索引指针）

#### 3.2.5 hashtable
1. [ ] 哈希表是由一个Entry数组构成的，每一个Entry是一个链表结构
2. [ ] 每一个Entry的key是一个sds数据结构，value是一个RedisObject


### 3.3 渐进式hash
✅ 当哈希表中元素的数量超过一定阈值时，Redis 需要扩展哈希表的容量  
✅ 传统哈希表扩容时，通常会一次性将所有旧表中的元素迁移到新的哈希表中。这种方式虽然直观，但如果哈希表非常大，扩容操作可能会消耗大量时间，导致 Redis 在此期间不能响应客户端请求，造成性能抖动  
✅ Redis将哈希表的扩展工作分散到多次请求中完成，每次只迁移部分数据，从而减少对客户端的影响，保证 Redis 的响应性能  
✅ 在 Redis 的主循环中，每次处理客户端请求时，Redis 会检查是否有需要进行的渐进式哈希  
✅ 在渐进式哈希过程中，Redis 会同时使用 ht[0] 和 ht[1]。读操作会先查找 ht[0]，如果未找到，再查找 ht[1]  
✅ 写操作则会根据是否在扩容过程中，将新数据直接插入到 ht[1]，从而避免在 ht[0] 中插入新数据  
✅ 每次迁移一个桶的数据后，rehashidx 会递增，当 rehashidx 达到 ht[0] 的容量上限时，说明所有数据已经迁移完毕，此时，Redis 将 ht[0] 设置为 ht[1]，将 ht[1] 清空，迁移过程完成 


## 四 Redis的key的过期策略
🔍 **结论:** Redis是通过"惰性删除" + "定期删除" 两种机制来进行key过期策略删除的  

### 4.1 惰性删除(Lazy Deletion)
🧠 **机制:**  
✅ 当你访问某个key的时候,如(GET / SET / EXISTS 等), Redis 会先检查它是否过期  
✅ 如果已过期，立即删除，不返回数据  
✅ 如果 没过期，照常处理  

🎯 **优点:**  
1. [ ] 只有在被访问的时候, 才会被删除，而不是集中一下删除，降低了系统压力，提升了性能
2. [ ] 对CPU友好

🎯 **缺点:**  
1. [ ] 有的key可能永久不会访问，会导致永久不删除，会占用着内存，对内存不友好
2. [ ] 删除速度存在延迟

### 4.2 定期删除(Active Expire Cycle)
🧠 **机制:**  
✅ Redis每隔一段时间，会从设置了到期时间的key随机抽取一部分，来判断是否到期  
✅ 一次最多检查 20 个 key  
✅ 如果发现过期 key，立即删除  
✅ 如果过期的key占据当前检查的key的25%，那么就再进行一轮，比如20个key有5个到期，则会再进行一轮  

🎯 **优点:**
1. [ ] 可以清理那些从不被访问的过期 key，不会一直占据内存空间

🎯 **缺点:**
1. [ ] 删除速度无法保证精确，可能略延迟

### 4.3 主动删除
🧠 **机制:**  
✅ 如果内存达到设置的maxmemory上限，Redis 会根据你的内存淘汰策略，主动回收部分 key  
✅ 此时过期 key 会优先被清理  

## 五 Redis的缓存淘汰策略
🔍 **结论:** 如果内存达到设置的maxmemory上限，需要淘汰内存中一部分的key，如果没有配置淘汰策略，默认就是抛出异常  

### 5.1 不淘汰
#### 5.1.1 NOEVICTION (不淘汰)
✅ 不进行任何key的淘汰，这个是默认的淘汰策略  
✅ Redis不允许任何的写请求, 超内存时直接报错  
✅ 但是允许读请求  

### 5.2 针对有到期时间的key淘汰，无论是否有到期时间
#### 5.2.1 VOLATILE-LRU(最近很少使用的有到期时间的KEY)
✅ 对所有设置了到期的时间的key，选择最近很少使用的key进行淘汰。这种策略可能会把频繁访问的key给淘汰掉

#### 5.2.2 VOLATILE-LFU(最近使用次数最少的有到期时间的KEY)
✅ 对所有设置了到期的时间的key，选择最近使用较少的、不频繁使用的key淘汰掉

#### 5.2.3 VOLATILE-TTL(到期时间较短的KEY)
✅ 对所有设置了到期的时间的key，选择距离到期时间最短的key，也就是ttl值较小的key进行淘汰

#### 5.2.4 VOLATILE-RANDOM(随机的有到期时间较的KEY)
✅ 对所有设置了到期的时间的key，随机选择设置了到期时间的key进行淘汰

### 5.3 针对所有key淘汰，无论是否有到期时间
#### 5.3.1 LLKEYS-LRU(最近很少使用的所有的KEY)
✅ 对所有的key，选择最近很少使用的key进行淘汰。这种策略可能会把不需要淘汰的key给淘汰掉。

#### 5.3.2 ALLKEYS-LFU(最近使用次数最少的所有的KEY)
✅ 对所有的key，选择最近使用频率很低的key进行淘汰。这种策略可能会把不需要淘汰的key给淘汰掉。

#### 5.3.3 ALLKEYS-RANDOM(随机的所有KEY)
✅ 对所有的key，随机选择一些key进行淘汰。这种策略可能会把不需要淘汰的key给淘汰掉。


## 六 Redis持久化
### 6.1 RDB持久化机制
#### 6.1.1 什么是RDB持久化
✅ RDB持久化指的是将Redis某一时刻内存数据进行快照，生成一个.rdb结尾的快照文件，用于宕机恢复  

#### 6.1.2 RDB持久化有什么特点
✅ RRB快照文件是压缩后的二进制文件，占用体积小，存储方便  
✅ RDB是全量快照  
✅ RDB备份的是内存中的数据，而不是指令  
✅ RDB备份精度低，发生数据丢失风险大  

#### 6.1.3 触发RDB
🎯 **手动触发:**  
✅ 通过执行bgsave,就会立刻进行快照  
✅ 手动触发不会阻塞当前进程，而是fork一个子进程来处理  

🎯 **自动触发:**    
✅ 首先需要在配置文件中配置save m n, 表示在m秒有n次写入，则会触发RDB快照。比如save 900 10, 表示只要在900秒内有10次写入则会触发自动快照操作  
✅ 自动触发save操作，会阻塞当前进程，然后进行快照操作，直到快照操作完成  
✅ 自动触发机制本质上也是调用bgsave，不会阻塞主线程，fork一个子进程来处理  



### 6.2 AOF持久化机制
#### 6.2.1 AOF持久化机制是什么
✅ AOF持久化指的是每次执行一条写入指令的时候，需要将指令以追加的形式写入到一个文件中，用于宕机恢复  

#### 6.2.2 AOF持久化机制有什么特点
✅ AOF文件是文本文件，占用体积大  
✅ AOF是增量备份  
✅ AOF存储的是指令，而不是内存中的数据  


#### 6.2.3 AOF重写
🧠 **为什么需要AOF重写?**   
✅ 随着写入的指令越来越多，AOF文件越来越大，导致磁盘空间浪费和宕机回复时间变长

🧠 **AOF重写工作原理**    
✅ 将已经删除或者到期的key的相关指令全部删除  
✅ 一个key写入多次，那么以最后一次写入为准，其余之前的写入可以删除  
✅ 在AOF重写过程中，Redis还是在处理其他的新的指令，为防止数据丢失，会先把这些指令放到一个缓冲区  
✅ 等AOF重写完成，Redis会将这些缓存的命令也追加到新的 AOF 文件中，确保所有的写操作都被记录  
✅ 重写完成后，Redis将旧的 AOF 文件替换为新的 AOF 文件，完成文件的更新，减少了文件大小，并提高了恢复的效率  

#### 6.2.4 触发重写 
🎯 **手动重写**  
✅ 用户通过命令bgwriteof手动触发AOF重写操作  
✅ Redis会在后台fork一个新的进程执行重写操作，不会阻塞主线程对客户端请求的处理  

🎯 **自动重写**  
✅ 首先需要在配置文件进行一些配置，比如大小达到多少、数量达到多少开始重写  
✅ auto-aof-rewrite-percentage: 当前AOF文件的大小超过上一次重写后AOF文件大小的百分比时开始触发重写, 如果是100，则表示超过上次AOF2倍大小  
✅ auto-aof-rewrite-min-size: 设置AOF文件触发重写的最小阈值, 这样可以避免在文件很小的时候频繁触发重写  

### 6.3 RDB持久化机制和AOF机制比较
### 6.3.1 相似点
✅ 都是Redis持久化机制，都可以用于Redis容灾恢复

### 6.3.2 不同点
🎯 **备份内容**  
✅ rdb: 数据  
✅ aof: 指令  

🎯 **备份方式**  
✅ rdb: 全量备份  
✅ aof: 增量备份   

🎯 **文件大小**  
✅ rdb: 体积小  
✅ aof: 体积大  

🎯 **恢复速度**  
✅ rdb: 快  
✅ aof: 慢  

🎯 **备份精度**  
✅ rdb: 稍微差一点，不能实现秒级备份  
✅ aof: 可以实现秒级备份，甚至每一个指令都可以备份  

🎯 **数据丢失风险**  
✅ rdb: 发生数据丢失风险较大  
✅ aof: 发生数据丢失风险较小  


### 6.4 恢复数据的流程
✅ 第一: Redis启动的时候，检查AOF是否开启  
✅ 第二: 如果开启则加载AOF恢复数据  
✅ 第三: 如果AOF没有开启，则检查RDB是否开启  
✅ 第四: 如果RDB开启，则通过RDB加载数据  
✅ 第五: 如果RDB也没有开启，则不会加载任何数据  

### 6.5 生产环境最佳实践
✅ 如果你可以忍受数分钟数据丢失，那就可以只使用RDB  
✅ 如果不允许的话推荐两种都使用，RDB用于容灾备份，便于传输，而且数据恢复速度快  
✅ 其他情况就可以使用AOF恢复数据  
✅ 所以不建议单独使用AOF  

## 七 Redis的一致性哈希原理
### 7.1 一致性哈希算法背景
✅ 对于有N个节点的缓存服务器集群，通过对key进行hash计算，得到的哈希值对节点数量取模，从而可以计算出这个key应该落在哪一个节点  
✅ 但是当增加或者删除节点的时候，集群节点数量发生变化，可能导致这个key计算出来的节点缓存未命中，而可能很多的key都可能缓存未命中，大面积失效，从而可能会导致缓存雪崩等问题  

### 7.2 一致性哈希算法
✅ 假设有2^32个点构成一个圆形的环，每一个点我们可以叫做token，这个圆形的环也叫作哈希环  
✅ 针对缓存服务器每一个节点Node, 进行hash计算，然后对2^32取模，计算落在哪一个token上：hash(node) % 2^32  
✅ 针对缓存的key计算一个哈希值，然后也对2^32取模，看落在哪一个token上: hash(key) % 2^32  
✅ 当key计算出来的token刚好落在节点所在的token,那么意味着这个key就应该落在这个node节点上  
✅ 如果token不是某一个node所在，那么就会顺时针往前查找，最近的一个node, 然后将key落在这个节点上  
✅ 当增加或者删除节点的时候，也只是影响一小部分key缓存未命中，而不会造成大面积失效，前提是节点在哈希环上分布不要倾斜的太离谱  

### 7.3 一致性哈希算法有什么问题
✅ 一致性哈希问题，有一个致命缺陷那就是节点倾斜，就是服务器数量比较少的情况下，然后服务器在哈希环上分布的很近，可能某个节点上有很多的key, 当这个删除的时候或者在中间增加一个节点的时候，还是可能会发生大面积key未命中，大面积缓存失效  
✅ 这种情况一般发生在节点比较少的情况下，那么我们尝试多增加一些节点，那这种情况就可以减缓或者避免  

### 7.4 一致性哈希算法的解决办法
✅ 在节点比较少的情况下，那么我们尝试多增加一些节点，那这种情况就可以减缓或者避免节点倾斜，但是就是没多少成本，不能加服务器了。怎么办?  
✅ 办法是我们可以虚拟出一些节点，让这些节点映射到真实的服务器上   
✅ 比如现在只有A、B、C三个节点，我们可以虚拟出A1、A2、A3…An, B1、B2、B3…Bn, C1、C2、C3…Cn，然后这些虚拟服务器通过某种算法映射到A、B、C对应的服务器上  
1. [ ] 第一: 讲这些虚拟服务器通过公式hash(node) % 2^32，然后落在哈希环上
2. [ ] 第二: 计算key应该落在哈希环上哪一个token?  hash(key) % 2^32
3. [ ] 第三: 然后顺时针往前寻找是哪一个服务器，如果是真实服务器，直接从这服务器上读写key
4. [ ] 第四: 如果是虚拟服务器，则根据虚拟服务器找到对应的真实服务器，然后通过真实服务器进行读写
5. [ ] 第五: 后续如果增加服务器，那么就不存在缓存服务器节点倾斜的问题了

### 7.5 Redis集群是如何解决一致性哈希的问题的(虚拟槽)
✅ 第一: Redis集群并没有使用一致性哈希算法的虚拟节点方式来解决节点倾斜的问题，而是通过虚拟槽的方式来解决节点倾斜问题    
✅ 第二: Redis集群会构建16384个哈希槽，这些哈希槽会均匀分布在Redis集群节点中，并且会维护一个哈希槽和节点的映射关系  
✅ 第三: 计算key落在哪一个节点，首先通过hash(key) % 16384 = slot, 看落在哪一个槽内    
✅ 第四: 然后根据槽找到槽所在节点，然后这个key就落在这个节点上  
✅ 第五: 当新增节点或者删除节点的时候，只需要迁移部分槽位到其他或者新的节点就可以，然后槽位内的数据，也一并移动过去  

### 7.6 为什么Redis使用哈希虚拟槽的方式而不是一致性哈希虚拟节点的方式？
📌 **简化客户端的实现**  
✅ 客户端可能需要根据节点数量，然后计算落在哪一个节点  
✅ 如果是虚拟节点，那么客户端就需要维护这个虚拟节点信息  
✅ 如果是哈希槽不用关心节点数量，直接通过哈希函数Crc16对key进行哈希，然后对16384取模就可以  

📌 **负载均衡与扩展**  
✅ 哈希槽模型的设计可以更好地支持负载均衡和扩展。当 Redis 需要扩展集群时，添加新节点后，只需将一部分哈希槽分配给新节点。由于哈希槽数量是固定的，因此集群扩展不会涉及到大规模的数据重新分布  


## 八 Redis集群和部署
### 8.1 主从模式
🔍 **特点:**  
✅ 第一: 主从复制就是Redis部署多个节点，有一个是主节点，有多个是从节点  
✅ 第二: 主节点负责读写数据；同步数据到从节点，从节点只负责读数据  
✅ 第三: 主从复制这个模式主要是提升Redis的读性能提升  

🎯 **优点:**  
✅ 可以提升读的性能

🎯 **缺点:**  
✅ 主从模式也无法提升写的性能:因为所有写请求都是在主节点处理后，同步到从节点, 写的性能压力都在主节点  
✅ 主从模式无法解决单点问题: 因为一旦主节点挂了，不会自动恢复，只能通过手动方式切换  

### 8.2 哨兵模式
🔍 **特点:**  
✅ 第一: 因为Redis主从模式无法解决主节点故障后，进行自动切换，所以引入了哨兵模式，用于监控主节点和从节点  
✅ 第二: 每一个Redis节点都会对应一个哨兵节点  
✅ 第三: 哨兵节点通过向主从节点发送PING消息，如果没有收到PONG消息，从而来判断是不是主观下线   
✅ 第四: 如果是主观下线，则当前哨兵节点向其他哨兵节点发起投票，超过大多数哨兵节点认为该节点下线，则认为该节点客观下线  
✅ 第五: 基于Gossip协议进行消息和状态传播  
✅ 第六: 如果下线的是主节点，则哨兵节点会发起选举，重新选举一个主节点  


🎯 **优点:**  
✅ 可以监控整个哨兵集群的主从节点的运行状况  
✅ 自动进行故障检测和主从切换  
✅ 主从切换后，可以通知其他从节点更新配置，然后主节点切换到新选举的节点；也可以通知发布订阅模式通知客户端主节点发生变化  

🎯 **缺点:**  
✅ 第一: 还是无法解决写性能瓶颈问题  
✅ 第二: 主从异步复制数据，还是无法避免数据丢失的问题  


### 8.3 集群模式
✅ 第一: 基于Sentinel哨兵集群模式，虽然可以解决主节点故障后自动选主的功能，但是没有办法解决写性能的提升  
✅ 第二: Cluster集群模式下，集群是由多个Redis节点组成，每一个节点负责一部分虚拟槽，数据自动分片到每一个Redis节点，每一个Redis节点负责存储一部分数据  
✅ 第三: Cluster集群模式采用无中心节点架构，每一个节点都是对等的，节点之间通过Gossip协议进行通信  
✅ 第四: Clsuter集群模式支持动态扩容和缩容，自动扩容和缩容，都会自动将数据在集群之间重新分配  
✅ 第五: Redis Cluster, 为了保证数据高可用，每一个主节点必须有从节点，否则主节点故障，导致主节点上数据无法被访问  


### 8.4 Sentinel是如何选举主节点的
✅ 当如果主节点被认定为客观下线，那么哨兵节点就会基于Raft协议进行选举主节点了  
✅ 哨兵节点会从其余从节点中选择一个主节点，只要某一个从节点超过半数以上的哨兵节点的认可，就可以作为主节点了  
✅ 选举的时候，还会参考一些客观因素：  
1. [ ] 第一: 从节点和主节点断开的时长
2. [ ] 第二: 从节点优先级
3. [ ] 第三: 从节点从主节点同步的offset大小
4. [ ] 第四: 实例id



## 九 Redis集群有用到gossip协议，怎么体现的
🔍 **结论:** Redis 集群在节点间的通信和状态同步中使用了Gossip 协议的一部分特性，来实现节点状态传播、故障检测和元数据更新等功能

### 9.1 什么是 Gossip 协议
✅ Gossip 协议是一种分布式系统中的去中心化通信协议，它允许节点之间以松散、随机的方式交换彼此的状态信息。Gossip 协议的优点是它的高容错性、去中心化和渐进传播的特性，使其非常适合大型分布式系统中的节点状态同步和容错处理  
✅ 节点之间周期性地互相通信，每个节点在相互通信的过程中交换自己的状态信息以及从其他节点接收到的状态信息  
✅ 状态信息逐步传播：通过节点之间的通信，集群中的状态信息逐渐传播到所有节点，最终所有节点都能获得整个集群的全局视图  
✅ 去中心化：Gossip 协议没有单一的中央控制节点，所有节点之间的通信是随机的、点对点的  

### 9.2 Redis 集群中 Gossip 协议的体现
#### 9.2.1 节点状态传播
✅ 在 Redis 集群中，所有节点需要定期交换彼此的状态信息，以维护整个集群的健康状态  
✅ 定期 PING 和 PONG 消息   
1. [ ] 每个节点会周期性地向其他随机选择的节点发送 PING 消息，接收方节点会返回 PONG 消息

✅ 状态信息更新  
1. [ ] 在 PING 和 PONG 消息中，节点不仅仅是交换彼此的健康状态，还会携带关于集群中其他节点的状态信息。  
2. [ ] 这种状态信息会包含当前节点认为其他节点的状态，比如某个节点是否处于下线状态（FAIL），以及该节点管理的哈希槽分布信息  

✅ 状态传播机  
1. [ ] 收到 PING 或 PONG 消息的节点会通过将消息中包含的状态信息进一步传播给其他节点，这样，集群中所有节点的状态会逐渐在集群中传播，最终每个节点都会掌握整个集群的状态  

#### 9.2.2 故障检测与主从切换
✅ Redis 集群通过节点之间的 Gossip 通信机制来实现节点的故障检测和主从切换  
✅ 主节点故障检测   
1. [ ] 当一个 Redis 节点检测到某个节点长时间没有响应 PING 消息时，它会将该节点标记为疑似下线（PFAIL）。但是单个节点不能直接确定一个节点故障，其他节点也需要确认这一状态  

✅ 集群协商机制  
1. [ ] 如果多个节点都检测到某个主节点处于疑似下线状态，并通过 Gossip 机制交换了这一信息后，集群内的其他主节点就会协商确认该节点的确故障（FAIL 状态）  

✅ 主从切换  
1. [ ] 一旦确认某个主节点故障，负责该主节点哈希槽的从节点会被选举为新的主节点，完成主从切换  

#### 9.2.3 元数据更新传播
✅ Redis 集群使用 Gossip 协议来传播集群元数据的更新信息，包括哈希槽分布和节点角色（主节点/从节点）等信息  
✅ 哈希槽迁移  
1. [ ] 当 Redis 集群进行扩容或缩容时，某些哈希槽可能会从一个节点迁移到另一个节点。这种迁移操作的元数据信息（如某个哈希槽被重新分配到哪个节点）需要在集群中传播开来  
2. [ ] 通过 Gossip 的传播机制，集群中的其他节点会逐渐接收到这一哈希槽迁移的更新信息，确保整个集群中的节点对哈希槽的分布有一致的理解  

✅ 节点角色变更  
1. [ ] 当主从节点切换时，节点的角色变化也会通过 Gossip 机制在集群中传播，其他节点会收到该节点从“主节点”变为“从节点”的信息，并更新其内部的集群状态视图


## 十 Redis 大key问题
### 10.1 什么是 Redis大Key？
单个key占用内存非常大(比如几十 MB，甚至几百 MB)
集合类型list、set、zset、hash中元素非常多
或者执行相关命令时间特别久

### 10.2 识别 Redis 大 key 的方法
使用 MEMORY USAGE <key> 查看 key 占用空间(Redis 4.0+)
使用 SCAN + 类型判断 + MEMORY USAGE
使用 redis-cli --bigkeys

### 10.3 Redis 大 key 的危害
| 问题         | 说明                                      |
| ---------- | --------------------------------------- |
| 命令阻塞       | 一次性读取或删除大 key（如 `DEL`, `HGETALL`）会阻塞主线程 |
| 内存不均衡      | 某个 key 占了大量空间，导致内存淘汰策略难以生效              |
| 慢查询/阻塞其他请求 | 影响 Redis 的整体响应时间，甚至卡顿                   |
| 迁移困难       | 如果使用了主从或分片，大 key 会严重拖慢迁移速度              |

### 10.4 解决 Redis 大 key 的 5 大思路
#### 10.4.1 拆分大 key
✅ 将大 key 拆成多个小 key 存储 例子：
1. [ ] 原来: user:10001:friends 是一个包含 10 万个好友的 set
2. [ ] 拆成：user:10001:friends:0、user:10001:friends:1... 每个 key 装一部分

✅ 将大List或者Set拆分成多个小的List或者Set
* 优点：分批操作、减少阻塞  
* 搭配分页读取，能显著降低单次命令耗时  

#### 10.4.2 避免使用阻塞性命令
比如:  
| 类型   | 高危命令示例                      |
| ---- | --------------------------- |
| List | `LRANGE`, `LREM`, `LTRIM`   |
| Hash | `HGETALL`, `HDEL`           |
| Set  | `SMEMBERS`, `SREM`          |
| ZSet | `ZRANGE`, `ZREM`, `ZPOPMAX` |


**替代方案**：使用分页命令（如 SSCAN、HSCAN、ZSCAN 等）  

#### 10.4.3 控制 key 的元素数量和 TTL
✅ 对 list/set/zset/hash 元素数量设上限，如超过 10k 就不再写入  
✅ 给非永久 key 加上 EXPIRE，避免长时间积累为大 key  
```java
// Java写入校验
public void saveUserProfile(String userId, String json) {
    if (json.length() > MAX_SIZE) {
        throw new RuntimeException("Value too large");
    }
    redis.set("user:" + userId, json);
}
```

#### 10.4.4 异步删除（Redis 4.0+）
✅ 使用 UNLINK 替代 DEL：UNLINK big_key  
✅ 它会将删除操作放入后台异步执行，避免主线程阻塞   

#### 10.4.5 在应用层处理大对象存储
✅ 对于特别大的结构或 JSON 数据，建议：  
1. [ ] Redis只存对象的索引或 ID
2. [ ] 分布式缓存中不要存大块数据



### 10.5 最终建议
✅ 生产环境Value超过100KB必须拆分
✅ 集合元素超过5000需评估拆分
✅ 每日扫描大Key并发送告警邮件
✅ 新功能设计阶段规避大Key产生